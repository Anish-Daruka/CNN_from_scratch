{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWNQr4yhyC7H",
        "outputId": "1c6ebd28-f5c1-448f-b328-6cb0af2e6c3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtlPOS5I133E"
      },
      "source": [
        "making a digit classifier using one layer neural network and comparing it with one built using cnn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ya_oyIf2B4e",
        "outputId": "fe4a114c-e55a-4b1c-9a06-dc2bb29133b9"
      },
      "outputs": [],
      "source": [
        "#loading the datasets from mnist custom data in a regular manner\n",
        "train = datasets.MNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
        "test = datasets.MNIST(root='./data', train=False, download=True, transform=ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng2zxaPH3x6r",
        "outputId": "fd986874-c93c-4e50-f6c5-45140d60cf53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torchvision.datasets.mnist.MNIST'>\n",
            "torch.Size([60000, 28, 28])\n",
            "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
            "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
            "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
            "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
            "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
            "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
            "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
            "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
            "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
            "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
            "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
            "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
            "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
            "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
            "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
            "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
            "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
            "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000]]]), 5)\n"
          ]
        }
      ],
      "source": [
        "#visualizing the data\n",
        "print(type(train))\n",
        "print(train.data.shape)#gives the imgs only\n",
        "a=train[0]\n",
        "print(a)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G69vNaMe4C1g",
        "outputId": "2eb96c68-0a5e-4b26-d211-3c1d3c920c7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n"
          ]
        }
      ],
      "source": [
        "digits=train.classes\n",
        "print(digits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "ftpoyyF-6hCq",
        "outputId": "28ab4dfd-cca6-4f97-a6c7-30e00790b37a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image, label = train[0]\n",
        "plt.imshow(image.squeeze(),cmap=\"gray\") # image shape is [1, 28, 28] (colour channels, height, width),so to remove the extra dimension 1,image.squeeze->(28,28)\n",
        "plt.title(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMpSoP3-82Be",
        "outputId": "46caf096-a5a6-48ff-9711-e897c21d1088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No seed:\n",
            "tensor([0.3904, 0.6009, 0.2566])\n",
            "tensor([0.7936, 0.9408, 0.1332])\n",
            "\n",
            "With seed:\n",
            "tensor([0.8823, 0.9150, 0.3829])\n",
            "tensor([0.8823, 0.9150, 0.3829])\n"
          ]
        }
      ],
      "source": [
        "#use of torch.manual_seed\n",
        "# Without setting a seed\n",
        "print(\"No seed:\")\n",
        "print(torch.rand(3))  # Generates 3 random numbers\n",
        "print(torch.rand(3))\n",
        "\n",
        "# With seed ,basically sets the same starting point always\n",
        "torch.manual_seed(42)\n",
        "print(\"\\nWith seed:\")\n",
        "print(torch.rand(3))  # These will be the same every time you run it\n",
        "\n",
        "torch.manual_seed(42)\n",
        "print(torch.rand(3))  # Re-setting the seed gives same output again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "id": "hAfwJ6rB9qKx",
        "outputId": "ee227b0d-fa92-41af-f431-bcb78ddb5517"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 900x900 with 16 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot more images\n",
        "torch.manual_seed(42)\n",
        "fig = plt.figure(figsize=(9, 9))\n",
        "rows, cols = 4, 4\n",
        "for i in range(1, rows * cols + 1):\n",
        "    random_idx = torch.randint(0, len(train), size=[1]).item()\n",
        "    img, label = train[random_idx]\n",
        "    fig.add_subplot(rows, cols, i)#adding subplot for img\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "    plt.title(digits[label])\n",
        "    plt.axis(False);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyUB42oJemHK"
      },
      "source": [
        "With mini-batches (small portions of the data), gradient descent is performed more often per epoch (once per mini-batch rather than once per epoch(i.e. over the whole dataset) ).we don't use independant data,since that can cause large variance and overshooting.All data in mini batches are computed parallely"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21BnnTJ4-ctx",
        "outputId": "f83590f0-5074-4b74-f6f0-e1ad0f0d81d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875\n",
            "313\n"
          ]
        }
      ],
      "source": [
        "#preparing dataloader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Setup the batch size hyperparameter\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Turn datasets into iterables (batches)\n",
        "train_data = DataLoader(train, # dataset to turn into iterable\n",
        "    batch_size=BATCH_SIZE, # how many samples per batch?\n",
        "    shuffle=True # shuffle data every epoch?\n",
        ")\n",
        "print(len(train_data))\n",
        "\n",
        "\n",
        "test_data = DataLoader(test,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False # don't necessarily have to shuffle the testing data\n",
        ")\n",
        "print(len(test_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch: 0 | X shape: torch.Size([32, 1, 28, 28]) | y shape: torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "for batch, (X, y) in enumerate(train_data):\n",
        "    print(f\"Batch: {batch} | X shape: {X.shape} | y shape: {y.shape}\")\n",
        "    if batch == 0:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUDTOE2UhJ36",
        "outputId": "65f62f85-82fa-4ec1-d758-eb0abe973ee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x13e8ecc20>\n",
            "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "print(train_data)\n",
        "train_features_batch, train_labels_batch = next(iter(train_data))\n",
        "print(train_features_batch.shape, train_labels_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "backpropagation->just like chain rule dw/dx=dW/dy*dy/dx,you change the weights of hidden layer based on what should be value of output,and then of input layer based on hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgK_2EWq_LPJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "digit_classifier(\n",
            "  (layer_stack): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
            "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 1/4 [00:03<00:11,  3.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train loss: 0.40561 | Test loss: 0.29465, Test acc: 91.58%\n",
            "\n",
            "Epoch: 1\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 2/4 [00:07<00:07,  3.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train loss: 0.30794 | Test loss: 0.28615, Test acc: 91.81%\n",
            "\n",
            "Epoch: 2\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 3/4 [00:10<00:03,  3.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train loss: 0.29560 | Test loss: 0.28648, Test acc: 91.89%\n",
            "\n",
            "Epoch: 3\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:14<00:00,  3.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train loss: 0.29078 | Test loss: 0.28677, Test acc: 91.76%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#define one layer linear neural network \n",
        "class digit_classifier(nn.Module):\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.layer_stack = nn.Sequential(\n",
        "            nn.Flatten(), #flattens the pixels,reduces the dimension\n",
        "            nn.Linear(in_features=input_shape, out_features=hidden_units), # in_features = number of features in a data sample (784 pixels)\n",
        "            nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer_stack(x)\n",
        "    \n",
        "model=digit_classifier(input_shape=784,hidden_units=10,output_shape=10)\n",
        "print(model) #gives the parameters of the model\n",
        "#define accuracy and optimizer function\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item()\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc\n",
        "loss_fn = nn.CrossEntropyLoss() # this is also called \"criterion\"/\"cost function\" in some places\n",
        "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.1)\n",
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "torch.manual_seed(42)\n",
        "epochs = 4\n",
        "\n",
        "# Create training and testing loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    print(f\"Epoch: {epoch}\\n-------\")\n",
        "    train_loss = 0\n",
        "    for batch, (X, y) in enumerate(train_data):\n",
        "        model.train() \n",
        "        # 1. Forward pass\n",
        "        y_pred = model(X)  \n",
        "\n",
        "        # 2. Calculate loss (per batch)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss # accumulatively add up the loss per epoch \n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print out how many samples have been seen\n",
        "        if batch % 400 == 0:\n",
        "            print(f\"Looked at {batch * len(X)}/{len(train_data.dataset)} samples\")\n",
        "\n",
        "    # Divide total train loss by length of train dataloader (average loss per batch per epoch)\n",
        "    train_loss /= len(train_data)\n",
        "    \n",
        "    ### Testing\n",
        "    # Setup variables for accumulatively adding up loss and accuracy \n",
        "    test_loss, test_acc = 0, 0 \n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in test_data:\n",
        "            # 1. Forward pass\n",
        "            test_pred = model(X)     \n",
        "           \n",
        "            # 2. Calculate loss (accumulatively)\n",
        "            test_loss += loss_fn(test_pred, y) # accumulatively add up the loss per epoch\n",
        "\n",
        "            # 3. Calculate accuracy (preds need to be same as y_true)\n",
        "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "        \n",
        "        # Calculations on test metrics need to happen inside torch.inference_mode()\n",
        "        # Divide total test loss by length of test dataloader (per batch)\n",
        "        test_loss /= len(test_data)\n",
        "\n",
        "        # Divide total accuracy by length of test dataloader (per batch)\n",
        "        test_acc /= len(test_data)\n",
        "\n",
        "    ## Print out what's happening\n",
        "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")#lr="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ey35pZZkiq2q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "digit_classifier1(\n",
            "  (layer_stack): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=10, out_features=10, bias=True)\n",
            "    (4): ReLU()\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 1/4 [00:04<00:12,  4.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train loss: 0.62218 | Test loss: 0.47458, Test acc: 85.06%\n",
            "\n",
            "Epoch: 1\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 2/4 [00:08<00:08,  4.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train loss: 0.40282 | Test loss: 0.27032, Test acc: 92.39%\n",
            "\n",
            "Epoch: 2\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 3/4 [00:11<00:03,  3.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train loss: 0.26528 | Test loss: 0.24858, Test acc: 92.73%\n",
            "\n",
            "Epoch: 3\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:15<00:00,  3.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train loss: 0.24698 | Test loss: 0.23527, Test acc: 93.35%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#applying non-linearity to neural network \n",
        "class digit_classifier1(nn.Module):\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.layer_stack = nn.Sequential(\n",
        "            nn.Flatten(), #flattens the pixels,reduces the dimension\n",
        "            nn.Linear(in_features=input_shape, out_features=hidden_units), \n",
        "            nn.ReLU(),#max(x,0)\n",
        "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
        "            nn.ReLU() # Adding non-linearity with ReLU activation function\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer_stack(x)\n",
        "    \n",
        "model=digit_classifier1(input_shape=784,hidden_units=10,output_shape=10)\n",
        "print(model) #gives the parameters of the model\n",
        "#define accuracy and optimizer function\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item()\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc\n",
        "loss_fn = nn.CrossEntropyLoss() # this is also called \"criterion\"/\"cost function\" in some places\n",
        "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.1)\n",
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "torch.manual_seed(42)\n",
        "epochs = 4\n",
        "\n",
        "# Create training and testing loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    print(f\"Epoch: {epoch}\\n-------\")\n",
        "    train_loss = 0\n",
        "    for batch, (X, y) in enumerate(train_data):\n",
        "        model.train() \n",
        "        # 1. Forward pass\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # 2. Calculate loss (per batch)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss # accumulatively add up the loss per epoch \n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print out how many samples have been seen\n",
        "        if batch % 400 == 0:\n",
        "            print(f\"Looked at {batch * len(X)}/{len(train_data.dataset)} samples\")\n",
        "\n",
        "    # Divide total train loss by length of train dataloader (average loss per batch per epoch)\n",
        "    train_loss /= len(train_data)\n",
        "    \n",
        "    ### Testing\n",
        "    # Setup variables for accumulatively adding up loss and accuracy \n",
        "    test_loss, test_acc = 0, 0 \n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in test_data:\n",
        "            # 1. Forward pass\n",
        "            test_pred = model(X)\n",
        "           \n",
        "            # 2. Calculate loss (accumulatively)\n",
        "            test_loss += loss_fn(test_pred, y) # accumulatively add up the loss per epoch\n",
        "\n",
        "            # 3. Calculate accuracy (preds need to be same as y_true)\n",
        "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "        \n",
        "        # Calculations on test metrics need to happen inside torch.inference_mode()\n",
        "        # Divide total test loss by length of test dataloader (per batch)\n",
        "        test_loss /= len(test_data)\n",
        "\n",
        "        # Divide total accuracy by length of test dataloader (per batch)\n",
        "        test_acc /= len(test_data)\n",
        "\n",
        "    ## Print out what's happening\n",
        "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")#lr="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This shows that for digit classification,the negative weights has a highly significant impact."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "digit_classifier2(\n",
            "  (layer_stack): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=784, out_features=50, bias=True)\n",
            "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
            "    (3): Linear(in_features=10, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 1/4 [00:04<00:13,  4.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train loss: 0.43459 | Test loss: 0.30496, Test acc: 91.28%\n",
            "\n",
            "Epoch: 1\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 2/4 [00:08<00:08,  4.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train loss: 0.32656 | Test loss: 0.29467, Test acc: 91.69%\n",
            "\n",
            "Epoch: 2\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 3/4 [00:12<00:04,  4.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train loss: 0.31192 | Test loss: 0.30231, Test acc: 91.42%\n",
            "\n",
            "Epoch: 3\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:17<00:00,  4.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train loss: 0.30744 | Test loss: 0.29512, Test acc: 91.88%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#lets see what happens if I increase one of the hidden units \n",
        "class digit_classifier2(nn.Module):\n",
        "    def __init__(self, input_shape: int, hidden_units1: int,hidden_units2: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.layer_stack = nn.Sequential(\n",
        "            nn.Flatten(), #flattens the pixels,reduces the dimension\n",
        "            nn.Linear(in_features=input_shape, out_features=hidden_units1), # in_features = number of features in a data sample (784 pixels)\n",
        "            nn.Linear(in_features=hidden_units1, out_features=hidden_units2), # in_features = number of features in a data sample (784 pixels)\n",
        "            nn.Linear(in_features=hidden_units2, out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer_stack(x)\n",
        "    \n",
        "model=digit_classifier2(input_shape=784,hidden_units1=50,hidden_units2=10,output_shape=10)\n",
        "print(model) #gives the parameters of the model\n",
        "#define accuracy and optimizer function\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item()\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc\n",
        "loss_fn = nn.CrossEntropyLoss() # this is also called \"criterion\"/\"cost function\" in some places\n",
        "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.1)\n",
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "torch.manual_seed(42)\n",
        "epochs = 4\n",
        "\n",
        "# Create training and testing loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    print(f\"Epoch: {epoch}\\n-------\")\n",
        "    train_loss = 0\n",
        "    for batch, (X, y) in enumerate(train_data):\n",
        "        model.train() \n",
        "        # 1. Forward pass\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # 2. Calculate loss (per batch)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss # accumulatively add up the loss per epoch \n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print out how many samples have been seen\n",
        "        if batch % 400 == 0:\n",
        "            print(f\"Looked at {batch * len(X)}/{len(train_data.dataset)} samples\")\n",
        "\n",
        "    # Divide total train loss by length of train dataloader (average loss per batch per epoch)\n",
        "    train_loss /= len(train_data)\n",
        "    \n",
        "    ### Testing\n",
        "    # Setup variables for accumulatively adding up loss and accuracy \n",
        "    test_loss, test_acc = 0, 0 \n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in test_data:\n",
        "            # 1. Forward pass\n",
        "            test_pred = model(X)\n",
        "           \n",
        "            # 2. Calculate loss (accumulatively)\n",
        "            test_loss += loss_fn(test_pred, y) # accumulatively add up the loss per epoch\n",
        "\n",
        "            # 3. Calculate accuracy (preds need to be same as y_true)\n",
        "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "        \n",
        "        # Calculations on test metrics need to happen inside torch.inference_mode()\n",
        "        # Divide total test loss by length of test dataloader (per batch)\n",
        "        test_loss /= len(test_data)\n",
        "\n",
        "        # Divide total accuracy by length of test dataloader (per batch)\n",
        "        test_acc /= len(test_data)\n",
        "\n",
        "    ## Print out what's happening\n",
        "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")#lr="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "adding layer is also not of a large importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Structured data (Excel spreadsheets, row and column data)->Gradient boosted models, Random Forests, XGBoost\tsklearn.ensemble, XGBoost library\n",
        "Unstructured data (images, audio, language)->Convolutional Neural Networks, Transformers\ttorchvision.models, HuggingFace Transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "digit_classifier(\n",
            "  (block_1): Sequential(\n",
            "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (block_2): Sequential(\n",
            "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "digit_classifier(\n",
            "  (block_1): Sequential(\n",
            "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (block_2): Sequential(\n",
            "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 1/4 [00:41<02:05, 41.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train loss: 0.33272 | Test loss: 0.07398, Test acc: 97.60%\n",
            "\n",
            "Epoch: 1\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 2/4 [01:24<01:25, 42.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train loss: 0.08174 | Test loss: 0.06402, Test acc: 98.01%\n",
            "\n",
            "Epoch: 2\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 3/4 [02:03<00:40, 40.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train loss: 0.06413 | Test loss: 0.05497, Test acc: 98.15%\n",
            "\n",
            "Epoch: 3\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [02:42<00:00, 40.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train loss: 0.05475 | Test loss: 0.05737, Test acc: 98.09%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a convolutional neural network \n",
        "class digit_classifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Model architecture copying TinyVGG from: \n",
        "    https://poloclub.github.io/cnn-explainer/\n",
        "    \"\"\"\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape, \n",
        "                      out_channels=hidden_units, \n",
        "                      kernel_size=3, # how big is the square that's going over the image?\n",
        "                      stride=1, # default\n",
        "                      padding=1),# options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units, \n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride=2) # maximum value in each convolutional block (2x2 square of pixels->1x1 of output)\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            # Where did this in_features shape come from? \n",
        "            # It's because each layer of our network compresses and changes the shape of our input data.\n",
        "            nn.Linear(in_features=hidden_units*7*7, \n",
        "                      out_features=output_shape)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.block_2(x)\n",
        "        # print(x.shape)\n",
        "        x = self.classifier(x)\n",
        "        # print(x.shape)\n",
        "        return x\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model = digit_classifier(input_shape=1, \n",
        "    hidden_units=10, \n",
        "    output_shape=10)\n",
        "print(model) #gives the parameters of the model\n",
        "#define accuracy and optimizer function\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item()\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc\n",
        "loss_fn = nn.CrossEntropyLoss() # this is also called \"criterion\"/\"cost function\" in some places\n",
        "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.1)\n",
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "torch.manual_seed(42)\n",
        "epochs = 4\n",
        "\n",
        "# Create training and testing loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    print(f\"Epoch: {epoch}\\n-------\")\n",
        "    train_loss = 0\n",
        "    for batch, (X, y) in enumerate(train_data):\n",
        "        model.train() \n",
        "        # 1. Forward pass\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # 2. Calculate loss (per batch)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss # accumulatively add up the loss per epoch \n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print out how many samples have been seen\n",
        "        if batch % 400 == 0:\n",
        "            print(f\"Looked at {batch * len(X)}/{len(train_data.dataset)} samples\")\n",
        "\n",
        "    # Divide total train loss by length of train dataloader (average loss per batch per epoch)\n",
        "    train_loss /= len(train_data)\n",
        "    \n",
        "    ### Testing\n",
        "    # Setup variables for accumulatively adding up loss and accuracy \n",
        "    test_loss, test_acc = 0, 0 \n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in test_data:\n",
        "            # 1. Forward pass\n",
        "            test_pred = model(X)\n",
        "           \n",
        "            # 2. Calculate loss (accumulatively)\n",
        "            test_loss += loss_fn(test_pred, y) # accumulatively add up the loss per epoch\n",
        "\n",
        "            # 3. Calculate accuracy (preds need to be same as y_true)\n",
        "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "        \n",
        "        # Calculations on test metrics need to happen inside torch.inference_mode()\n",
        "        # Divide total test loss by length of test dataloader (per batch)\n",
        "        test_loss /= len(test_data)\n",
        "\n",
        "        # Divide total accuracy by length of test dataloader (per batch)\n",
        "        test_acc /= len(test_data)\n",
        "\n",
        "    ## Print out what's happening\n",
        "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")#lr=\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "so CNN model accuracy=98.09%\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ -9.0175,  -5.6315,  -0.1971,  18.0503,  -5.5038,   8.1694, -12.6162,\n",
            "           0.6045,   3.6156,  -0.8242]])\n",
            "3\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGZBJREFUeJzt3X2MVNXdB/CzIKyo7OKKsKwsCIraoEBKlRIVXyAgWipqG239A40vAdEoVG23qaBtk7U0UWOl2j8a0dQXNClSrd1EUSBW0IhSYmzRRXSx8lKNu8BSwMB9cq8P+7AC+sy6u2d25vNJTpaZub+dw+Uy3zn3njlTkiRJEgCgk3Xr7CcEgJQAAiAKAQRAFAIIgCgEEABRCCAAohBAAEQhgACI4rCQZ/bu3Rs+/vjj0Lt371BSUhK7OwDkKF3fYNu2baGqqip069at6wRQGj7V1dWxuwHAN7Rhw4YwcODArnMKLh35AND1fd3reYcF0Pz588Pxxx8fDj/88DBmzJjw+uuv/7/qnHYDKAxf93reIQG0cOHCMHv27DB37tzw5ptvhpEjR4ZJkyaFLVu2dMTTAdAVJR3gjDPOSGbOnNlye8+ePUlVVVVSW1v7tbVNTU3p6tyapmla6NotfT3/Ku0+Atq9e3dYtWpVmDBhQst96SyI9PaKFSsO2H7Xrl1h69atrRoAha/dA+iTTz4Je/bsCf379291f3p706ZNB2xfW1sbysvLW5oZcADFIfosuJqamtDU1NTS0ml7ABS+dv8cUN++fUP37t3D5s2bW92f3q6srDxg+9LS0qwBUFzafQTUs2fPMHr06LBkyZJWqxukt8eOHdveTwdAF9UhKyGkU7CnTZsWvvOd74Qzzjgj3HfffaG5uTlcffXVHfF0AHRBHRJAl19+efjPf/4T5syZk008GDVqVKirqztgYgIAxasknYsd8kg6DTudDQdA15ZOLCsrK8vfWXAAFCcBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIjisDhPC/9/N998c8419957b8hnJSUlOdckSRI6y5w5c3KueeCBB3KuaWxszLmGwmEEBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACisBgpee+dd97Juaa5ublNz3XEEUeEztCZC4u2xV133ZVzzfjx43OumTdvXs41f/vb33KuIT8ZAQEQhQACoDAC6M4778y+62T/dsopp7T30wDQxXXINaDhw4eHF1988f+e5DCXmgBorUOSIQ2cysrKjvjVABSIDrkG9N5774WqqqowdOjQcOWVV4aGhoZDbrtr166wdevWVg2AwtfuATRmzJiwYMGCUFdXFx588MGwfv36cPbZZ4dt27YddPva2tpQXl7e0qqrq9u7SwAUQwBNnjw5/PCHPwwjRowIkyZNCs8//3xobGwMTz311EG3r6mpCU1NTS1tw4YN7d0lAPJQh88O6NOnTzjppJNCfX39QR8vLS3NGgDFpcM/B7R9+/awbt26MGDAgI5+KgCKOYBuvfXWsGzZsvDBBx+EV199NVxyySWhe/fu4Uc/+lF7PxUAXVi7n4L76KOPsrD59NNPw7HHHhvOOuussHLlyuzPALBPSZJnqyKm07DT2XDwTaQTYdpi1qxZbZr5mau33nor55p///vfOdcMGzYstMXJJ58cOsOOHTtyrvne976Xc016VobOl04sKysrO+Tj1oIDIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFFYjBT2c/TRR+dcM3z48Jxr3n333ZxrtmzZknPNoEGDQlvcdNNNOdfMnj07dIb0W5ZzNWXKlA7pC1/NYqQA5CUBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiOCzO00J++uyzz3KueeWVV0K+amhoaFPdunXrQr46/vjjY3eBdmIEBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACisBgpFLDS0tI21V166aXt3hf4MiMgAKIQQABEIYAAiEIAARCFAAIgCgEEQBQCCIAoBBAAUQggAKIQQABEIYAAiEIAARCFxUjpVBMmTMi5Zty4cR3Sl2Jw1llntanunHPOCZ3hgw8+yLnmgQce6JC+0PmMgACIQgAB0DUCaPny5WHKlCmhqqoqlJSUhGeeeabV40mShDlz5oQBAwaEXr16Zadc3nvvvfbsMwDFGEDNzc1h5MiRYf78+Qd9fN68eeH+++8PDz30UHjttdfCkUceGSZNmhR27tzZHv0FoFgnIUyePDlrB5OOfu67777wi1/8Ilx88cXZfY8++mjo379/NlK64oorvnmPASgI7XoNaP369WHTpk2tZjqVl5eHMWPGhBUrVhy0ZteuXWHr1q2tGgCFr10DKA2fVDri2V96e99jX1ZbW5uF1L5WXV3dnl0CIE9FnwVXU1MTmpqaWtqGDRtidwmArhZAlZWV2c/Nmze3uj+9ve+xLystLQ1lZWWtGgCFr10DaMiQIVnQLFmypOW+9JpOOhtu7Nix7flUABTbLLjt27eH+vr6VhMPVq9eHSoqKsKgQYPCLbfcEn7961+HYcOGZYF0xx13ZJ8Zmjp1anv3HYBiCqA33ngjnHfeeS23Z8+enf2cNm1aWLBgQbj99tuzzwpdf/31obGxMVuLqq6uLhx++OHt23MAurSSJP3wTh5JT9mls+HIf4f6PNhXWbx4cc413bt3z7mGzrf/mZGOPIbef//9nGuII51Y9lXX9aPPggOgOAkgAKIQQABEIYAAiEIAARCFAAIgCgEEQBQCCIAoBBAAUQggAKIQQABEIYAAiEIAAdA1vo6BwtO7d+821e37Ko5cWNm6cP3jH//IucbK1sXNCAiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARGExUtq8GOlJJ53U7n2h6+rfv3/ONeXl5TnXNDU15VxDfjICAiAKAQRAFAIIgCgEEABRCCAAohBAAEQhgACIQgABEIUAAiAKAQRAFAIIgCgEEABRlCRJkoQ8snXr1jYtUEjnGzVqVM41zz//fKcsctmZduzYkXPNu+++m3PNX//615xrLrrootAWI0aMyLmmW7fc388uXLgw55oZM2bkXGMB0zjS/V5WVnbIx42AAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUFiOlU7Vlkcvhw4eHfPbZZ5/lXFNXVxfyWUNDQ841xx13XOgM3//+9ztlIVe+OYuRApCXBBAAXSOAli9fHqZMmRKqqqpCSUlJeOaZZ1o9ftVVV2X3798uuOCC9uwzAMUYQM3NzWHkyJFh/vz5h9wmDZyNGze2tCeeeOKb9hOAAnNYrgWTJ0/O2lcpLS0NlZWV36RfABS4DrkGtHTp0tCvX79w8sknZ1+f++mnnx5y2127dmUz3/ZvABS+dg+g9PTbo48+GpYsWRJ+85vfhGXLlmUjpj179hx0+9ra2mza9b5WXV3d3l0CoBBOwX2dK664ouXPp512Wva5jxNOOCEbFY0fP/6A7WtqasLs2bNbbqcjICEEUPg6fBr20KFDQ9++fUN9ff0hrxelH1TavwFQ+Do8gD766KPsGtCAAQM6+qkAKORTcNu3b281mlm/fn1YvXp1qKioyNpdd90VLrvssmwW3Lp168Ltt98eTjzxxDBp0qT27jsAxRRAb7zxRjjvvPNabu+7fjNt2rTw4IMPhjVr1oRHHnkkNDY2Zh9WnThxYvjVr36VnWoDgH0sRgocYPr06TnXfNWH09uTxUi7DouRApCXBBAAUQggAKIQQABEIYAAiEIAARCFAAIgCgEEQBQCCIAoBBAAUQggAKIQQABEIYAAKIyv5Aa6vvPPPz92FygCRkAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAqLkeaxO++8M+eaWbNm5Vyzfv360BajRo1qUx35b9KkSbG7QBEwAgIgCgEEQBQCCIAoBBAAUQggAKIQQABEIYAAiEIAARCFAAIgCgEEQBQCCIAoBBAAUViMtJP84Ac/yLnmZz/7Wc41PXr0yLmmX79+oS2GDh2ac83777/fpucihNGjR+dcs3DhwjY915FHHhk6wx//+Meca15++eUO6QudzwgIgCgEEABRCCAAohBAAEQhgACIQgABEIUAAiAKAQRAFAIIgCgEEABRCCAAohBAAERhMdJOsmzZspxrPv7445xrBg8enHNN//79Q1s8++yzOddceOGFOdd8+OGHodCccsopnbI47ZAhQ0Jn+eSTT3Kuueeee3Ku2bFjR8415CcjIACiEEAA5H8A1dbWhtNPPz307t07+w6ZqVOnhrVr17baZufOnWHmzJnhmGOOCUcddVS47LLLwubNm9u73wAUUwCl1zHScFm5cmV44YUXwueffx4mTpwYmpubW7aZNWtWdm3g6aefzrZPr2NceumlHdF3AIplEkJdXV2r2wsWLMhGQqtWrQrjxo0LTU1N2TccPv744+H888/Ptnn44YfDt771rSy0vvvd77Zv7wEozmtAaeCkKioqsp9pEKWjogkTJrSa7TNo0KCwYsWKg/6OXbt2ha1bt7ZqABS+NgfQ3r17wy233BLOPPPMcOqpp2b3bdq0KfTs2TP06dPngGm+6WOHuq5UXl7e0qqrq9vaJQCKIYDSa0Fvv/12ePLJJ79RB2pqarKR1L62YcOGb/T7ACjgD6LeeOON4bnnngvLly8PAwcObLm/srIy7N69OzQ2NrYaBaWz4NLHDqa0tDRrABSXnEZASZJk4bNo0aLw0ksvHfAp69GjR4cePXqEJUuWtNyXTtNuaGgIY8eObb9eA1BcI6D0tFs6w23x4sXZZ4H2XddJr9306tUr+3nNNdeE2bNnZxMTysrKwk033ZSFjxlwALQ5gB588MHs57nnntvq/nSq9VVXXZX9+d577w3dunXLPoCaznCbNGlS+P3vf5/L0wBQBEqS9LxaHkmnYacjKUK47bbbcq65++67Qz579913c6555JFHcq75y1/+Etpi2LBhOddce+21OdeMGjUq55qqqqqQz9ryRjM9Q0LhSieWpWfCDsVacABEIYAAiEIAARCFAAIgCgEEQBQCCIAoBBAAUQggAKIQQABEIYAAiEIAARCFAAIgCgEEQBRWw85j1dXVOddcffXVnbYicfqdTxSmG264Ieea9LvCcrVt27aca+g6rIYNQF4SQABEIYAAiEIAARCFAAIgCgEEQBQCCIAoBBAAUQggAKIQQABEIYAAiEIAARCFxUgJffr0aVPdtddem3PNxIkTc64ZP358zjWFaPHixTnXvPrqq216rvvvvz/nmt27d7fpuShcFiMFIC8JIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIjCYqQAdAiLkQKQlwQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIP8DqLa2Npx++umhd+/eoV+/fmHq1Klh7dq1rbY599xzQ0lJSas2ffr09u43AMUUQMuWLQszZ84MK1euDC+88EL4/PPPw8SJE0Nzc3Or7a677rqwcePGljZv3rz27jcAXdxhuWxcV1fX6vaCBQuykdCqVavCuHHjWu4/4ogjQmVlZfv1EoCC0+2bft1qqqKiotX9jz32WOjbt2849dRTQ01NTdixY8chf8euXbuyr+HevwFQBJI22rNnT3LRRRclZ555Zqv7//CHPyR1dXXJmjVrkj/96U/Jcccdl1xyySWH/D1z585N0m5omqZpoaBaU1PTV+ZImwNo+vTpyeDBg5MNGzZ85XZLlizJOlJfX3/Qx3fu3Jl1cl9Lf1/snaZpmqaFDg+gnK4B7XPjjTeG5557LixfvjwMHDjwK7cdM2ZM9rO+vj6ccMIJBzxeWlqaNQCKS04BlI6YbrrpprBo0aKwdOnSMGTIkK+tWb16dfZzwIABbe8lAMUdQOkU7McffzwsXrw4+yzQpk2bsvvLy8tDr169wrp167LHL7zwwnDMMceENWvWhFmzZmUz5EaMGNFRfwcAuqJcrvsc6jzfww8/nD3e0NCQjBs3LqmoqEhKS0uTE088Mbntttu+9jzg/tJtY5+31DRN08I3bl/32l/yv8GSN9Jp2OmICoCuLf2oTllZ2SEftxYcAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFHkXQAlSRK7CwB0wut53gXQtm3bYncBgE54PS9J8mzIsXfv3vDxxx+H3r17h5KSklaPbd26NVRXV4cNGzaEsrKyUKzshy/YD1+wH75gP+TPfkhjJQ2fqqqq0K3bocc5h4U8k3Z24MCBX7lNulOL+QDbx374gv3wBfvhC/ZDfuyH8vLyr90m707BAVAcBBAAUXSpACotLQ1z587NfhYz++EL9sMX7Icv2A9dbz/k3SQEAIpDlxoBAVA4BBAAUQggAKIQQABE0WUCaP78+eH4448Phx9+eBgzZkx4/fXXQ7G58847s9Uh9m+nnHJKKHTLly8PU6ZMyT5Vnf6dn3nmmVaPp/No5syZEwYMGBB69eoVJkyYEN57771QbPvhqquuOuD4uOCCC0Ihqa2tDaeffnq2Ukq/fv3C1KlTw9q1a1tts3PnzjBz5sxwzDHHhKOOOipcdtllYfPmzaHY9sO55557wPEwffr0kE+6RAAtXLgwzJ49O5ta+Oabb4aRI0eGSZMmhS1btoRiM3z48LBx48aW9sorr4RC19zcnP2bp29CDmbevHnh/vvvDw899FB47bXXwpFHHpkdH+kLUTHth1QaOPsfH0888UQoJMuWLcvCZeXKleGFF14In3/+eZg4cWK2b/aZNWtWePbZZ8PTTz+dbZ8u7XXppZeGYtsPqeuuu67V8ZD+X8krSRdwxhlnJDNnzmy5vWfPnqSqqiqpra1NisncuXOTkSNHJsUsPWQXLVrUcnvv3r1JZWVl8tvf/rblvsbGxqS0tDR54oknkmLZD6lp06YlF198cVJMtmzZku2LZcuWtfzb9+jRI3n66adbtvnnP/+ZbbNixYqkWPZD6pxzzkluvvnmJJ/l/Qho9+7dYdWqVdlplf3Xi0tvr1ixIhSb9NRSegpm6NCh4corrwwNDQ2hmK1fvz5s2rSp1fGRrkGVnqYtxuNj6dKl2SmZk08+OcyYMSN8+umnoZA1NTVlPysqKrKf6WtFOhrY/3hIT1MPGjSooI+Hpi/th30ee+yx0Ldv33DqqaeGmpqasGPHjpBP8m4x0i/75JNPwp49e0L//v1b3Z/e/te//hWKSfqiumDBguzFJR1O33XXXeHss88Ob7/9dnYuuBil4ZM62PGx77FikZ5+S081DRkyJKxbty78/Oc/D5MnT85eeLt37x4KTbpy/i233BLOPPPM7AU2lf6b9+zZM/Tp06dojoe9B9kPqR//+Mdh8ODB2RvWNWvWhJ/+9KfZdaI///nPIV/kfQDxf9IXk31GjBiRBVJ6gD311FPhmmuuido34rviiita/nzaaadlx8gJJ5yQjYrGjx8fCk16DSR981UM10Hbsh+uv/76VsdDOkknPQ7SNyfpcZEP8v4UXDp8TN+9fXkWS3q7srIyFLP0Xd5JJ50U6uvrQ7Hadww4Pg6UnqZN//8U4vFx4403hueeey68/PLLrb6+Jf03T0/bNzY2FsXxcOMh9sPBpG9YU/l0POR9AKXD6dGjR4clS5a0GnKmt8eOHRuK2fbt27N3M+k7m2KVnm5KX1j2Pz7SL+RKZ8MV+/Hx0UcfZdeACun4SOdfpC+6ixYtCi+99FL277+/9LWiR48erY6H9LRTeq20kI6H5Gv2w8GsXr06+5lXx0PSBTz55JPZrKYFCxYk77zzTnL99dcnffr0STZt2pQUk5/85CfJ0qVLk/Xr1yd///vfkwkTJiR9+/bNZsAUsm3btiVvvfVW1tJD9p577sn+/OGHH2aP33333dnxsHjx4mTNmjXZTLAhQ4Yk//3vf5Ni2Q/pY7feems20ys9Pl588cXk29/+djJs2LBk586dSaGYMWNGUl5env0/2LhxY0vbsWNHyzbTp09PBg0alLz00kvJG2+8kYwdOzZrhWTG1+yH+vr65Je//GX290+Ph/T/xtChQ5Nx48Yl+aRLBFDqd7/7XXZQ9ezZM5uWvXLlyqTYXH755cmAAQOyfXDcccdlt9MDrdC9/PLL2Qvul1s67XjfVOw77rgj6d+/f/ZGZfz48cnatWuTYtoP6QvPxIkTk2OPPTabhjx48ODkuuuuK7g3aQf7+6ft4YcfbtkmfeNxww03JEcffXRyxBFHJJdcckn24lxM+6GhoSELm4qKiuz/xIknnpjcdtttSVNTU5JPfB0DAFHk/TUgAAqTAAIgCgEEQBQCCIAoBBAAUQggAKIQQABEIYAAiEIAARCFAAIgCgEEQBQCCIAQw/8A3VvLpEbyzxQAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#seeing some predictions\n",
        "import random\n",
        "a=test[random.randint(0, len(test)-1)]\n",
        "image, label = a\n",
        "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "    image = image.unsqueeze(dim=0)  # Add batch dimension \n",
        "    pred = model(image)\n",
        "    print(pred)\n",
        "    # Get the index of the highest score\n",
        "    pred_label = pred.argmax(dim=1).item()\n",
        "    print(pred_label)  # Get the predicted label\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
